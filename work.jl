#### workfile

using Random

mutable struct StatesVec{T<:Signed}
    states::Vector{T}
end

function StatesVec(len::Integer, vals::NTuple{N,T} = (Int8(-1), Int8(0), Int8(1)))::StatesVec{T} where {N,T}
    StatesVec(rand(vals, len))
end

function learn!(learner::StatesVec{T}, reality::StatesVec{T}, p₁::Real) where T
    idx = (reality.states .!= T(0)) .& (rand(length(learner.states)) .<= p₁)
    view(learner.states, idx) .= view(reality.states, idx)
end

function measure_compatibility(entity1::StatesVec{T}, entity2::StatesVec{T})::Integer where T
    sum(entity1.states .== entity2.states)
end

function count_views(dim::Integer, agents::AbstractVector{StatesVec{T}}, vals::NTuple{N,T} = (Int8(-1), Int8(0), Int8(1)))::Vector{Real} where {N,T}
    map(v->count(a->a.states[dim]==v, agents), collect(vals))
end

function calc_change_probability(dim::Integer, organizational_code::StatesVec{T}, agents::AbstractVector{StatesVec{T}}, p₂::Real, vals::NTuple{N,T} = (Int8(-1), Int8(0), Int8(1)))::Tuple{Real, Real} where {N,T}
    counted_views = count_views(dim, agents, vals)

    most_pop_val = vals[argmax(counted_views)]
    if vals[argmax(counted_views)] == organizational_code.states[dim]
        return (most_pop_val, 0)
    end

    idx = organizational_code.states[dim] .== collect(vals)
    (most_pop_val, 1 - (1 - p₂)^(sum(counted_views[.!idx]) - sum(counted_views[idx])))
end

function adjust!(organizational_code::StatesVec{T}, reality::StatesVec{T}, agents::AbstractVector{StatesVec{T}}, p₂::Real) where T
    comp_code = measure_compatibility(reality, organizational_code)
    better_comp_agents = view(agents, map(a->measure_compatibility(a, reality), agents) .> comp_code)

    for i in eachindex(organizational_code.states)
        most_pop_val, prob = calc_change_probability(i, organizational_code, agents, p₂)
        if rand() <=  prob
           organizational_code.states[i] = most_pop_val
        end
    end
end

function simulate(m::T, n::T, rep::T, p₁::U, p₂::U) where {T<:Integer, U<:Real}
    simulate(m, n, rep, fill(p₁, n), p₂)
end

function simulate(m::T, n::T, rep::T, p₁::Vector{U}, p₂::U) where {T<:Integer, U<:Real}
    agents = [StatesVec(m) for i in 1:n]
    org_code = StatesVec(fill(Int8(0), m))
    reality = StatesVec(m, (Int8(-1), Int8(1)))

    for i in 1:rep
        for j in eachindex(agents)
            learn!(agents[j], reality, p₁[j])
        end
        adjust!(org_code, reality, agents, p₂)
    end

    (measure_compatibility(org_code, reality)/m, sum(a->measure_compatibility(a, reality)/m, agents)/n)
end

res1 = map(p₁->simulate(30, 50, 80, p₁, 0.1), 0.1:0.1:0.9)